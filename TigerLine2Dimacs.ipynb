{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline to label DIMACS road networks with TIGER/Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: The purpose of this notebook is to attach category of each edge of DIMACS road networks.\n",
    "# Source: We use TIGER/Line dataset from DIMACS to attach categories to edges\n",
    "# Approach: \n",
    "#     1. We first download target road network from \n",
    "#       http://www.diag.uniroma1.it/challenge9/download.shtml, NY for the rest of description.\n",
    "#     2. Then we download all the TIGER/Line from \n",
    "#       http://www.diag.uniroma1.it/challenge9/data/tiger/, and we merge them into USA_ALL.tmp for reference.\n",
    "#       merge.cpp can be found at \"Merging of two or more files\" on the same webpage,\n",
    "#       and compile it to 'merge.out' before running\n",
    "#     3. We use USA_ALL.tmp as dictionary to guide the labeling process of target road network, and\n",
    "#       save it as USA-road-l.NY.gr in the format of DIMACS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkFlow:\n",
    "# http://www.diag.uniroma1.it/challenge9/data/tiger/merge.cpp\n",
    "# - Data preparation(with merge.out)\n",
    "#   |\n",
    "#   +- pullFromTigerLine()\n",
    "#   |\n",
    "#   +- unzipTigerLine()\n",
    "#   |\n",
    "#   +- mergetmps2USAALL()\n",
    "#   |\n",
    "#   +: Return: Now we have USA_ALL.tmp\n",
    "#\n",
    "# - Label given graph\n",
    "#   |\n",
    "#   +: Description: Given graph from Dimacs like NY, \n",
    "#      we label it with coor2id_dict and edge2wc_dict,\n",
    "#      and output to USA-road-l.NY.gr\n",
    "#   |\n",
    "#   +- labelGivenGr_with_USA_ALL()\n",
    "#   |\n",
    "#   +: Write as: USA-road-l.NY.gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we store this notebook to g_source_dir, and use it as our workspace\n",
    "g_source_dir = \"TIGERLine\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullFromTigerLine():\n",
    "    import os\n",
    "    import requests\n",
    "    \n",
    "    # Base URL\n",
    "    base_url = \"http://www.diag.uniroma1.it/challenge9/data/tiger/\"\n",
    "    \n",
    "    # List of state abbreviations (50 states + D.C.)\n",
    "    states = [\n",
    "        \"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\",\n",
    "        \"HI\", \"IA\", \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\", \"MD\", \"ME\",\n",
    "        \"MI\", \"MN\", \"MO\", \"MS\", \"MT\", \"NC\", \"ND\", \"NE\", \"NH\", \"NJ\", \"NM\",\n",
    "        \"NV\", \"NY\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\",\n",
    "        \"UT\", \"VA\", \"VT\", \"WA\", \"WI\", \"WV\", \"WY\"\n",
    "    ]\n",
    "    \n",
    "    # Directory to save files\n",
    "    save_dir = g_source_dir\n",
    "    print(\"Saving to \", save_dir)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Download each state's file\n",
    "    for state in states:\n",
    "        file_name = f\"{state}.tmp.gz\"\n",
    "        file_url = base_url + file_name\n",
    "        file_path = os.path.join(save_dir, file_name)\n",
    "    \n",
    "        print(f\"Downloading {file_name}...\")\n",
    "    \n",
    "        response = requests.get(file_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    file.write(chunk)\n",
    "            print(f\"Saved: {file_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {file_name}\")\n",
    "    \n",
    "    print(\"All downloads completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipTigerLine_Road():\n",
    "    import os\n",
    "    import gzip\n",
    "    import shutil\n",
    "    \n",
    "    # Directory containing the downloaded .tmp.gz files\n",
    "    source_dir = g_source_dir\n",
    "    \n",
    "    # Unzipping each file\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        if file_name.endswith(\".tmp.gz\"):  # Check for .tmp.gz files\n",
    "            gz_path = os.path.join(source_dir, file_name)\n",
    "            tmp_path = os.path.join(source_dir, file_name[:-3])  # Remove .gz extension\n",
    "    \n",
    "            print(f\"Unzipping {file_name}...\")\n",
    "    \n",
    "            with gzip.open(gz_path, 'rb') as gz_file:\n",
    "                with open(tmp_path, 'wb') as tmp_file:\n",
    "                    shutil.copyfileobj(gz_file, tmp_file)\n",
    "    \n",
    "            print(f\"Unzipped: {tmp_path}\")\n",
    "    \n",
    "    print(\"All files have been unzipped.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergetmps2USAALL():\n",
    "    import subprocess\n",
    "    #Thx to GPT for gerating list of 50 states of US\n",
    "    states = [\n",
    "        \"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\",\n",
    "        \"HI\", \"IA\", \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\", \"MD\", \"ME\",\n",
    "        \"MI\", \"MN\", \"MO\", \"MS\", \"MT\", \"NC\", \"ND\", \"NE\", \"NH\", \"NJ\", \"NM\",\n",
    "        \"NV\", \"NY\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\",\n",
    "        \"UT\", \"VA\", \"VT\", \"WA\", \"WI\", \"WV\", \"WY\"\n",
    "    ]\n",
    "    ech_str = \"\"\n",
    "    for ele in states:\n",
    "        tmpstr = g_source_dir+ele\n",
    "        ech_str+=tmpstr+\".tmp \"\n",
    "    print(ech_str)\n",
    "    \n",
    "    cmd_pre = 'echo \"'\n",
    "    # merge.cpp compiled as merge.out before running\n",
    "    cmd_post = '\" | ./merge.out USA_ALL.tmp'\n",
    "    \n",
    "    cmd=\"\"\n",
    "    cmd+=cmd_pre\n",
    "    cmd+=ech_str\n",
    "    cmd+=cmd_post\n",
    "    print(cmd)\n",
    "    \n",
    "    # Run the command\n",
    "    process = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    # Print the output\n",
    "    print(\"STDOUT:\", process.stdout)\n",
    "    print(\"STDERR:\", process.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullGrCo(GivenGrCo_name):\n",
    "    import requests\n",
    "    url = \"http://www.diag.uniroma1.it/challenge9/data/USA-road-d/USA-road-d.\"+GivenGrCo_name+\".gz\"\n",
    "    filename = \"USA-road-d.\"+GivenGrCo_name+\".gr.gz\"\n",
    "\n",
    "    # Send HTTP request\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Check if request was successful\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"Downloaded {filename} successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download {filename}. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "def pullFromDIMACS(GivenGr_Lis):\n",
    "   tmp_Lis = [] \n",
    "   tmp_Lis = GivenGr_Lis\n",
    "   for name in tmp_Lis:\n",
    "       pullGrCo(name+\".gr\") \n",
    "       pullGrCo(name+\".co\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "# TIGER/Line\n",
    "pullFromTigerLine()\n",
    "# Road networks\n",
    "pullGrCo_Lis = [\"NY\", \"COL\", \"FLA\", \"CAL\"]\n",
    "pullFromDIMACS(pullGrCo_Lis)\n",
    "# gunzip\n",
    "unzipTigerLine_Road()\n",
    "# output USA_ALL.tmp\n",
    "mergetmps2USAALL()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Given Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tiger_line_tmpfile(in_file):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "       @param in_file\n",
    "       It is a tiger line file. E.g. DC.tmp. Descriptions can be found on dimacs\n",
    "       http://www.diag.uniroma1.it/challenge9/data/tiger/\n",
    "    Return:\n",
    "        @param num_of_nodes\n",
    "        @param num_of_edges\n",
    "        @param coor2id_dict\n",
    "        @param edge2wc_dict\n",
    "        We return coor2id_dict using (lon, log) as key to ids, \n",
    "        and edge2wc_dict of (from_id, to_id) as key to (edge weight, category)\n",
    "    \"\"\"\n",
    "    print(\"read TIGER/LINE TMP file:\", in_file)\n",
    "    i=0\n",
    "    num_of_nodes = 0\n",
    "    num_of_edges = 0 \n",
    "    flag = 0\n",
    "    coor2id_dict = {}\n",
    "    edge2wc_dict = {}\n",
    "    with open(in_file, \"r\") as file:\n",
    "        for line in file:  # Read the file line by line\n",
    "            if 0 == i:\n",
    "                num_of_nodes = line\n",
    "                num_of_nodes = int(num_of_nodes)  \n",
    "                print(\"# nodes: \",num_of_nodes)\n",
    "                i += 1\n",
    "            elif i<num_of_nodes+1:\n",
    "                #e.g. 9550 -77036974 38910146\n",
    "                id, lon, log = line.split()\n",
    "                id = int(id)\n",
    "                lon = int(lon)\n",
    "                log = int(log)\n",
    "                coor2id_dict[(lon, log)] = id\n",
    "                # print(id, lon, log)\n",
    "                i += 1\n",
    "            elif i==num_of_nodes+1:\n",
    "                num_of_edges = line\n",
    "                num_of_edges = int(line)\n",
    "                print(\"# of edges: \", num_of_edges)\n",
    "                i += 1\n",
    "            # no need to add i as rest of file are edge infor\n",
    "            else:\n",
    "                if 0 == flag:\n",
    "                    src, des = line.split()\n",
    "                    src = int(src)\n",
    "                    des = int(des)\n",
    "                    edge2wc_dict[(src, des)] = (-1.0, -1)\n",
    "                    flag = 1\n",
    "                    # print(src, des)\n",
    "                elif 1==flag:\n",
    "                    trav_time, distance, category = line.split()\n",
    "                    trav_time = float(trav_time)\n",
    "                    distance = float(distance)\n",
    "                    category = int(category)\n",
    "                    edge2wc_dict[(src, des)] = (distance, category)\n",
    "                    flag = 0\n",
    "                    # print(trav_time, distance, category)\n",
    "    return num_of_edges, num_of_edges, coor2id_dict, edge2wc_dict \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGivenGr(in_file_co, in_file_gr):\n",
    "    print(\"read Given Graph: \", in_file_co, \" and \", in_file_gr)\n",
    "    GG_coor2id_dict = {}\n",
    "    GG_edge2wc_dict = {}\n",
    "    GG_edgeOrigOrder_Lis = []\n",
    "    i=0\n",
    "    with open(in_file_co, \"r\") as file:\n",
    "        for line in file:  # Read the file line by line\n",
    "            if i<7:\n",
    "                i+=1\n",
    "                continue\n",
    "            else:\n",
    "                v, id, lon, log = line.split()\n",
    "                id = int(id)\n",
    "                lon = int(lon)\n",
    "                log = int(log)\n",
    "                GG_coor2id_dict[(lon, log)] = id\n",
    "                # print(v, id, lon, log) \n",
    "    i=0\n",
    "    with open(in_file_gr, \"r\") as file:\n",
    "        for line in file:  # Read the file line by line\n",
    "            if i<7:\n",
    "                i+=1\n",
    "                continue\n",
    "            else:\n",
    "                a, uid, vid, dist = line.split()\n",
    "                # print(a, uid, vid, dist)\n",
    "                uid = int(uid)\n",
    "                vid = int(vid)\n",
    "                dist = int(dist)\n",
    "                GG_edge2wc_dict[(uid, vid)] = (dist, -1)\n",
    "                GG_edgeOrigOrder_Lis.append((uid, vid))\n",
    "    return GG_coor2id_dict, GG_edge2wc_dict, GG_edgeOrigOrder_Lis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelGivenGr_with_USA_ALL(GivenGr, l_size, n, m, coor2id_dict, edge2wc_dict):\n",
    "    '''\n",
    "    Members:\n",
    "        GGId2DictId: given NY ids we find correspondind ids in USA_ALL.tmp\n",
    "        DictId2GGId: reverse\n",
    "        GG_edgeOrigOrder_Lis: keep the orignal order we read from NY.gr\n",
    "        GG_edge2wc_dict: updated with edge category \n",
    "        key_lis: labels sorted in decending order of frequence\n",
    "        s and e:\n",
    "            |-s = e\n",
    "            |-e = math.floor(s+(len(key_lis) - i -1 )/l_size + 1)\n",
    "            s is the start pos of new label\n",
    "            e is the end pos of the new label\n",
    "            we rename the labels by shrinking label of similar frequncy into one new label\n",
    "        \n",
    "    Write:\n",
    "        we write GG_edge2wc_dict to file in DIMACS format.\n",
    "    '''\n",
    "    GG_coor2id_dict, GG_edge2wc_dict, GG_edgeOrigOrder_Lis = \\\n",
    "                readGivenGr(\"./\"+g_source_dir+\"/USA-road-d.\"+GivenGr+\".co\", \"./\"+g_source_dir+\"/USA-road-d.\"+GivenGr+\".gr\")\n",
    "    # get infor from USA_ALL.tmp dict \n",
    "    # node mapping\n",
    "    GGId2DictId = {}\n",
    "    DictId2GGId = {}\n",
    "    for key in GG_coor2id_dict.keys():\n",
    "        dictId = coor2id_dict[key]\n",
    "        GGId = GG_coor2id_dict[key]\n",
    "        GGId2DictId[GGId] = dictId\n",
    "        DictId2GGId[dictId] = GGId\n",
    "    cnt = 0\n",
    "    for key in GG_edge2wc_dict.keys():\n",
    "        # get dict id of given gr\n",
    "        (dictId_from, dictId_to) = (GGId2DictId[key[0]], GGId2DictId[key[1]])\n",
    "        (GG_wei, _) = GG_edge2wc_dict[key]\n",
    "        # get edge category from dict\n",
    "        if (dictId_from, dictId_to) in edge2wc_dict.keys():\n",
    "            (_, dict_cat) = edge2wc_dict[(dictId_from, dictId_to)]\n",
    "            # update given graph category\n",
    "            GG_edge2wc_dict[key] = (GG_wei, dict_cat)\n",
    "        elif (dictId_to, dictId_from) in edge2wc_dict.keys():\n",
    "            (_, dict_cat) = edge2wc_dict[(dictId_to, dictId_from)]\n",
    "            GG_edge2wc_dict[key] = (GG_wei, dict_cat)\n",
    "        else:\n",
    "            cnt+=1\n",
    "    print(cnt)\n",
    "    # rebalance categories into 10 categories as described in VLDB2024\n",
    "    category_dict = {}\n",
    "    for ele in GG_edgeOrigOrder_Lis:\n",
    "        (_, GG_cat) = GG_edge2wc_dict[ele]\n",
    "        if GG_cat in category_dict.keys():\n",
    "            category_dict[GG_cat]+=1\n",
    "        else:\n",
    "            category_dict[GG_cat] = 0\n",
    "    print(category_dict)\n",
    "    key_lis = []\n",
    "    for key in category_dict.keys():\n",
    "        key_lis.append((key, category_dict[key]))\n",
    "    key_lis.sort(reverse=True, key=lambda x:x[1])\n",
    "    print(key_lis)\n",
    "    import math\n",
    "    s = 0\n",
    "    e = 0\n",
    "    # l_size = 10\n",
    "    olde2new_label={}\n",
    "    print(len(key_lis))\n",
    "    # we map number segments to l_size segments\n",
    "    for i in range(l_size):\n",
    "        s = e\n",
    "        e = math.floor(s+(len(key_lis) - i -1 )/l_size + 1)\n",
    "        for j in range(s, e):\n",
    "           olde2new_label[key_lis[j][0]] = i\n",
    "    print(olde2new_label)\n",
    "    # USA-road-l.NY.gr\n",
    "    out_labeled_file = \"./\"+g_source_dir+\"/USA-road-l.\"+GivenGr+\".gr\"\n",
    "    with open(out_labeled_file, \"w\") as file:\n",
    "        file.write(\"c 9th DIMACS Implementation Challenge: Shortest Paths\\n\")\n",
    "        file.write(\"c http://www.dis.uniroma1.it/~challenge9\\n\")\n",
    "        file.write(\"c TIGER/Line nodes coords for graph \"+out_labeled_file+\"\\n\")\n",
    "        file.write(\"c\\n\")\n",
    "        file.write(\"p sp co \"+str(n)+\" \"+str(m)+\"\\n\")\n",
    "        file.write(\"c graph contains \"+str(n)+\" nodes and \"+str(m)+\" arcs\\n\")\n",
    "        file.write(\"c\\n\")\n",
    "        for ele in GG_edgeOrigOrder_Lis:\n",
    "            (GG_from, GG_to) = ele\n",
    "            (GG_wei, GG_category) = GG_edge2wc_dict[ele]\n",
    "            # we use ceil()*10 weight to keep same as weight from \n",
    "            # http://www.diag.uniroma1.it/challenge9/data/USA-road-d/USA-road-d.NY.gr.gz\n",
    "            # write relabeled category to file\n",
    "            file.write(\"a \"+str(GG_from)+\" \"+str(GG_to)+\" \"+str(GG_wei)+\" \"+str(olde2new_label[GG_category])+\"\\n\")\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read TIGER/LINE TMP file: ./TIGERLine/USA_ALL.tmp\n",
      "# nodes:  24412259\n",
      "# of edges:  29653988\n"
     ]
    }
   ],
   "source": [
    "TigeLineTmp = \"USA_ALL\"\n",
    "n, m, coor2id_dict, edge2wc_dict =  read_tiger_line_tmpfile(\"./\"+g_source_dir+\"/\"+TigeLineTmp+\".tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read Given Graph:  ./TIGERLine/USA-road-d.NY.co  and  ./TIGERLine/USA-road-d.NY.gr\n",
      "0\n",
      "{41: 692519, 15: 10993, 21: 4133, 25: 2895, 31: 13933, 35: 4837, 45: 845, 11: 3461, 44: 5, 42: 17, 12: 33, 37: 1, 38: 3, 43: 37, 48: 11, 13: 25, 16: 79, 46: 1}\n",
      "[(41, 692519), (31, 13933), (15, 10993), (35, 4837), (21, 4133), (11, 3461), (25, 2895), (45, 845), (16, 79), (43, 37), (12, 33), (13, 25), (42, 17), (48, 11), (44, 5), (38, 3), (37, 1), (46, 1)]\n",
      "18\n",
      "{41: 0, 31: 0, 15: 1, 35: 1, 21: 2, 11: 2, 25: 3, 45: 3, 16: 4, 43: 4, 12: 5, 13: 5, 42: 6, 48: 6, 44: 7, 38: 7, 37: 8, 46: 9}\n",
      "read Given Graph:  ./TIGERLine/USA-road-d.COL.co  and  ./TIGERLine/USA-road-d.COL.gr\n",
      "0\n",
      "{41: 987102, 11: 6453, 21: 24579, 31: 36338, 13: 389, 15: 835, 33: 27, 45: 91, 25: 575, 42: 73, 43: 299, 16: 35, 44: 41, 35: 151, 23: 31, 24: 1, 17: 3, 48: 9, 37: 1, 12: 1, 36: 3, 47: 3, 38: 3}\n",
      "[(41, 987102), (31, 36338), (21, 24579), (11, 6453), (15, 835), (25, 575), (13, 389), (43, 299), (35, 151), (45, 91), (42, 73), (44, 41), (16, 35), (23, 31), (33, 27), (48, 9), (17, 3), (36, 3), (47, 3), (38, 3), (24, 1), (37, 1), (12, 1)]\n",
      "23\n",
      "{41: 0, 31: 0, 21: 0, 11: 1, 15: 1, 25: 1, 13: 2, 43: 2, 35: 2, 45: 3, 42: 3, 44: 4, 16: 4, 23: 5, 33: 5, 48: 6, 17: 6, 36: 7, 47: 7, 38: 8, 24: 8, 37: 9, 12: 9}\n",
      "read Given Graph:  ./TIGERLine/USA-road-d.FLA.co  and  ./TIGERLine/USA-road-d.FLA.gr\n",
      "0\n",
      "{41: 2467040, 21: 88323, 15: 10385, 31: 84117, 25: 54289, 38: 17, 11: 2376, 13: 369, 43: 309, 45: 1829, 35: 3361, 42: 77, 24: 31, 23: 61, 46: 7, 44: 39, 33: 63, 47: 17, 22: 19, 14: 3, 32: 33, 12: 1, 48: 9}\n",
      "[(41, 2467040), (21, 88323), (31, 84117), (25, 54289), (15, 10385), (35, 3361), (11, 2376), (45, 1829), (13, 369), (43, 309), (42, 77), (33, 63), (23, 61), (44, 39), (32, 33), (24, 31), (22, 19), (38, 17), (47, 17), (48, 9), (46, 7), (14, 3), (12, 1)]\n",
      "23\n",
      "{41: 0, 21: 0, 31: 0, 25: 1, 15: 1, 35: 1, 11: 2, 45: 2, 13: 2, 43: 3, 42: 3, 33: 4, 23: 4, 44: 5, 32: 5, 24: 6, 22: 6, 38: 7, 47: 7, 48: 8, 46: 8, 14: 9, 12: 9}\n",
      "read Given Graph:  ./TIGERLine/USA-road-d.CAL.co  and  ./TIGERLine/USA-road-d.CAL.gr\n",
      "0\n",
      "{41: 4422956, 31: 122548, 48: 339, 21: 31689, 11: 35239, 15: 20871, 43: 1153, 13: 663, 25: 2249, 17: 31, 45: 16827, 44: 233, 12: 9, 42: 145, 16: 17, 33: 77, 14: 13, 35: 1583, 23: 25, 18: 867, 22: 3, 32: 17, 24: 5, 38: 43, 37: 51, 47: 39, 46: 15, 36: 5, 26: 1}\n",
      "[(41, 4422956), (31, 122548), (11, 35239), (21, 31689), (15, 20871), (45, 16827), (25, 2249), (35, 1583), (43, 1153), (18, 867), (13, 663), (48, 339), (44, 233), (42, 145), (33, 77), (37, 51), (38, 43), (47, 39), (17, 31), (23, 25), (16, 17), (32, 17), (46, 15), (14, 13), (12, 9), (24, 5), (36, 5), (22, 3), (26, 1)]\n",
      "29\n",
      "{41: 0, 31: 0, 11: 0, 21: 1, 15: 1, 45: 1, 25: 2, 35: 2, 43: 2, 18: 3, 13: 3, 48: 3, 44: 4, 42: 4, 33: 4, 37: 5, 38: 5, 47: 5, 17: 6, 23: 6, 16: 6, 32: 7, 46: 7, 14: 7, 12: 8, 24: 8, 36: 8, 22: 9, 26: 9}\n"
     ]
    }
   ],
   "source": [
    "GivenGr_Lis = [\"NY\", \"COL\", \"FLA\", \"CAL\"]\n",
    "GivenGr_lis=[]\n",
    "for GivenGr in GivenGr_Lis: \n",
    "    labelGivenGr_with_USA_ALL(GivenGr, 10, n, m, coor2id_dict, edge2wc_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
